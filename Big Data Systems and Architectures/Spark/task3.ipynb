{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Big Data Systems and Architectures - Spark Assignment 2021</h2>\n",
    "<h3>Exploring International Flights in 2017 Data</h3>\n",
    "\n",
    "---\n",
    "> Georgia Vlassi p2822001<br />\n",
    "> Business Anlytics <br />\n",
    "> Athens University of Economics and Business <br/>\n",
    "\n",
    "---\n",
    "\n",
    "The main scope of this assignment is to analyse a dataset about international flights in 2017, using Apache Spark to reveal insights about these data. \n",
    "\n",
    "You can find the aforementioned data here:\n",
    "http://andrea.imis.athena-innovation.gr/aueb-master/flights.csv.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <h3>Task 3</h3>\n",
    "As a final task, your supervisor assigned to you to investigate if it is possible to train a linear \n",
    "regression model that could predict the departure delay a flight may have by using, as input, \n",
    "its origin (column “ORIGIN”), its airways (column “CARRIER”), and its departure time (column \n",
    "“DEP_TIME”). Again you should use Python and DataFrames, this time with MLlib. You should \n",
    "pay attention to transform the string-based input features using the proper representation \n",
    "format, and you should explain your choices. Special attention should be given to the\n",
    "“DEP_TIME” column: your supervisor told you that you should only consider the \n",
    "corresponding hour of the day (which, of course, should be transformed in a one-hot \n",
    "representation). For your training and testing workflow you should first remove outliers (see \n",
    "Task 2) and then split your dataset into two parts, one that will be used for training reasons \n",
    "and it will contain 70% of the entries, and a second one containing the remaining entries and \n",
    "which will be used for the assessment of the model. No need to implement a more \n",
    "sophisticated evaluation process (e.g., based on k-fold) is required in this phase. Your code \n",
    "should (a) prepare the feature vectors, (b) prepare the training and testing datasets, (c) train \n",
    "the model, (d) print on the screen the first 10 predictions, i.e., pairs of feature vectors (in \n",
    "compact format) and predicted outputs, on the screen, and (e) evaluate the accuracy of the \n",
    "model and display the corresponding metric on the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "#Import the following\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.readwriter import DataFrameReader\n",
    "from pyspark.sql.types import IntegerType, Row, StringType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col,percent_rank,count,avg,expr,desc,round,when,isnan\n",
    "\n",
    "#Import ML\n",
    "import pyspark.mllib\n",
    "import pyspark.mllib.regression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "#Import Linear Regression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to create a temporary view to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FlightsAssignment</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f968590f8b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"FlightsAssignment\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initialising the view we have to load our data. The data file named '671009038_T_ONTIME_REPORTING.csv', will be read by using using spark and save them into flights_data variable. In order to access the data download the file mentioned on description and unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "flights_data = spark.read\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".option(\"inferSchema\",\"true\")\\\n",
    ".csv(\"671009038_T_ONTIME_REPORTING.csv\")\n",
    "\n",
    "#Clear dataset from null values\n",
    "flights_data=flights_data.filter(flights_data.DEP_DELAY.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------+--------+\n",
      "|DEP_DELAY|ORIGIN|CARRIER|DEP_TIME|\n",
      "+---------+------+-------+--------+\n",
      "|     -7.0|   AVL|     9E|    1658|\n",
      "|     -8.0|   JFK|     9E|    1122|\n",
      "|     -7.0|   CLE|     9E|    1334|\n",
      "|     -1.0|   BHM|     9E|    1059|\n",
      "|     -3.0|   GTF|     9E|    1057|\n",
      "|      0.0|   GRB|     9E|     855|\n",
      "|     -5.0|   AGS|     9E|     800|\n",
      "|    -10.0|   CLT|     9E|    1350|\n",
      "|     -4.0|   MEM|     9E|    1441|\n",
      "|     -4.0|   MSP|     9E|     847|\n",
      "+---------+------+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('DEP_DELAY', 'double'),\n",
       " ('ORIGIN', 'string'),\n",
       " ('CARRIER', 'string'),\n",
       " ('DEP_TIME', 'int')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keep only the four columns\n",
    "flights_data = flights_data.select(\"DEP_DELAY\",\"ORIGIN\",\"CARRIER\",\"DEP_TIME\")\n",
    "flights_data.show(10)\n",
    "\n",
    "#Count unique values of ORIGIN \n",
    "flights_data.select(\"ORIGIN\").distinct().count()\n",
    "\n",
    "#Count unique values of CARRIER \n",
    "flights_data.select(\"CARRIER\").distinct().count()\n",
    "\n",
    "#Check types\n",
    "flights_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DEP_DELAY', 'double'),\n",
       " ('ORIGIN', 'string'),\n",
       " ('CARRIER', 'string'),\n",
       " ('DEP_TIME', 'string')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the type of DEP_TIME to string\n",
    "flights_data = flights_data.withColumn(\"DEP_TIME\",flights_data[\"DEP_TIME\"].cast(T.StringType()))\n",
    "\n",
    "# converted DEP_TIME\n",
    "flights_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------+--------+\n",
      "|DEP_DELAY|ORIGIN|CARRIER|DEP_TIME|\n",
      "+---------+------+-------+--------+\n",
      "|     -7.0|   AVL|     9E|    1658|\n",
      "|     -8.0|   JFK|     9E|    1122|\n",
      "|     -7.0|   CLE|     9E|    1334|\n",
      "|     -1.0|   BHM|     9E|    1059|\n",
      "|     -3.0|   GTF|     9E|    1057|\n",
      "|      0.0|   GRB|     9E|    0855|\n",
      "|     -5.0|   AGS|     9E|    0800|\n",
      "|    -10.0|   CLT|     9E|    1350|\n",
      "|     -4.0|   MEM|     9E|    1441|\n",
      "|     -4.0|   MSP|     9E|    0847|\n",
      "+---------+------+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "[('DEP_DELAY', 'double'), ('ORIGIN', 'string'), ('CARRIER', 'string'), ('DEP_TIME', 'string')]\n"
     ]
    }
   ],
   "source": [
    "#Fill with zeros if length = 3 digits \n",
    "flights_data = flights_data.withColumn('DEP_TIME', F.format_string(\"%04d\", F.col('DEP_TIME').cast(\"int\"))) \n",
    "flights_data.show(10)\n",
    "\n",
    "#Convert it type to string\n",
    "flights_data = flights_data.withColumn(\"DEP_TIME\",flights_data[\"DEP_TIME\"].cast(T.StringType()))\n",
    "print(flights_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------+--------+-------------+\n",
      "|DEP_DELAY|ORIGIN|CARRIER|DEP_TIME|DEP_TIME_HOUR|\n",
      "+---------+------+-------+--------+-------------+\n",
      "|     -7.0|   AVL|     9E|    1658|           16|\n",
      "|     -8.0|   JFK|     9E|    1122|           11|\n",
      "|     -7.0|   CLE|     9E|    1334|           13|\n",
      "|     -1.0|   BHM|     9E|    1059|           10|\n",
      "|     -3.0|   GTF|     9E|    1057|           10|\n",
      "|      0.0|   GRB|     9E|    0855|           08|\n",
      "|     -5.0|   AGS|     9E|    0800|           08|\n",
      "|    -10.0|   CLT|     9E|    1350|           13|\n",
      "|     -4.0|   MEM|     9E|    1441|           14|\n",
      "|     -4.0|   MSP|     9E|    0847|           08|\n",
      "|     -5.0|   ATL|     9E|    1856|           18|\n",
      "|     -9.0|   AGS|     9E|    1427|           14|\n",
      "|     -6.0|   ATL|     9E|    1259|           12|\n",
      "|     -6.0|   CVG|     9E|    0834|           08|\n",
      "|     -1.0|   RDU|     9E|    1324|           13|\n",
      "|     -5.0|   GSO|     9E|    1155|           11|\n",
      "|    124.0|   BIS|     9E|    0809|           08|\n",
      "|     -4.0|   ATL|     9E|    1531|           15|\n",
      "|     -4.0|   LGA|     9E|    1756|           17|\n",
      "|     -1.0|   PIT|     9E|    1124|           11|\n",
      "+---------+------+-------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+\n",
      "|DEP_TIME_HOUR|\n",
      "+-------------+\n",
      "|           07|\n",
      "|           15|\n",
      "|           11|\n",
      "|           01|\n",
      "|           22|\n",
      "|           16|\n",
      "|           18|\n",
      "|           00|\n",
      "|           17|\n",
      "|           09|\n",
      "|           05|\n",
      "|           19|\n",
      "|           23|\n",
      "|           08|\n",
      "|           03|\n",
      "|           02|\n",
      "|           06|\n",
      "|           20|\n",
      "|           10|\n",
      "|           12|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create new column with only two digts\n",
    "flights_data = flights_data.withColumn(\"DEP_TIME_HOUR\", flights_data.DEP_TIME.substr(1,2))\n",
    "flights_data.show()\n",
    "\n",
    "flights_data.dtypes\n",
    "\n",
    "flights_data.select(\"DEP_TIME_HOUR\").distinct().count()  \n",
    "\n",
    "#Replace if the hour=24 to 00\n",
    "flights_data = flights_data.withColumn(\"DEP_TIME_HOUR\", F.regexp_replace(\"DEP_TIME_HOUR\", \"24\", \"00\"))\n",
    "\n",
    "# see the nu value \n",
    "flights_data.select(\"DEP_TIME_HOUR\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+\n",
      "|ORIGIN|count|     percent_rank_ap|\n",
      "+------+-----+--------------------+\n",
      "|   AKN|   61|                 0.0|\n",
      "|   PGV|   77|0.002785515320334262|\n",
      "|   DLG|   82|0.005571030640668524|\n",
      "|   GST|   82|0.005571030640668524|\n",
      "|   HYA|   83|0.011142061281337047|\n",
      "|   ADK|   98|0.013927576601671309|\n",
      "|   OWB|  101|0.016713091922005572|\n",
      "|   OGD|  104|0.019498607242339833|\n",
      "|   PPG|  120|0.022284122562674095|\n",
      "|   STC|  130|0.025069637883008356|\n",
      "|   BFM|  152|0.027855153203342618|\n",
      "|   HGR|  182| 0.03064066852367688|\n",
      "|   SMX|  193|0.033426183844011144|\n",
      "|   XWA|  205|0.036211699164345405|\n",
      "|   ART|  210| 0.03899721448467967|\n",
      "|   BKG|  221| 0.04178272980501393|\n",
      "|   GUC|  238| 0.04456824512534819|\n",
      "|   WYS|  264| 0.04735376044568245|\n",
      "|   OTH|  361| 0.05013927576601671|\n",
      "|   PSM|  423|0.052924791086350974|\n",
      "+------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------+------+-------+--------+-------------+------------------+\n",
      "|DEP_DELAY|ORIGIN|CARRIER|DEP_TIME|DEP_TIME_HOUR|   percent_rank_ap|\n",
      "+---------+------+-------+--------+-------------+------------------+\n",
      "|     -4.0|   BGM|     OO|    1743|           17|0.2479108635097493|\n",
      "|    -12.0|   BGM|     OO|    1221|           12|0.2479108635097493|\n",
      "|     -7.0|   BGM|     OO|    0553|           05|0.2479108635097493|\n",
      "|     28.0|   BGM|     OO|    1815|           18|0.2479108635097493|\n",
      "|     44.0|   BGM|     OO|    1317|           13|0.2479108635097493|\n",
      "|     -3.0|   BGM|     OO|    0557|           05|0.2479108635097493|\n",
      "|     29.0|   BGM|     OO|    1816|           18|0.2479108635097493|\n",
      "|     68.0|   BGM|     OO|    1341|           13|0.2479108635097493|\n",
      "|     -7.0|   BGM|     OO|    0553|           05|0.2479108635097493|\n",
      "|    -10.0|   BGM|     OO|    1737|           17|0.2479108635097493|\n",
      "|     -1.0|   BGM|     OO|    1219|           12|0.2479108635097493|\n",
      "|     -5.0|   BGM|     OO|    0910|           09|0.2479108635097493|\n",
      "|     -7.0|   BGM|     OO|    0540|           05|0.2479108635097493|\n",
      "|     -4.0|   BGM|     OO|    1742|           17|0.2479108635097493|\n",
      "|    -10.0|   BGM|     OO|    0537|           05|0.2479108635097493|\n",
      "|     13.0|   BGM|     OO|    1759|           17|0.2479108635097493|\n",
      "|    506.0|   BGM|     OO|    1413|           14|0.2479108635097493|\n",
      "|     -9.0|   BGM|     OO|    1737|           17|0.2479108635097493|\n",
      "|     -7.0|   BGM|     OO|    0540|           05|0.2479108635097493|\n",
      "|    -11.0|   BGM|     OO|    1735|           17|0.2479108635097493|\n",
      "+---------+------+-------+--------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Handle outliers at ORIGIN and CARRIER columns\n",
    "#ORIGIN\n",
    "percentiles_ap = flights_data.groupBy(\"ORIGIN\").count()\\\n",
    "                .select(\"ORIGIN\",\"count\", percent_rank().over(Window.partitionBy().orderBy(\"count\")).alias(\"percent_rank_ap\"))\n",
    "                \n",
    "percentiles_ap.show()\n",
    "\n",
    "flights_percentiles_ap = flights_data.alias('flights').join(percentiles_ap.alias('percentiles'), col('percentiles.ORIGIN') == col('flights.ORIGIN'))\\\n",
    "            .select([col('flights.'+xx) for xx in flights_data.columns] + [col('percentiles.percent_rank_ap')])\n",
    "\n",
    "flights_percentiles_ap.show()\n",
    "\n",
    "#remove outliers (aka < 0.01) and store the rest on a new dataframe\n",
    "flights_data = flights_percentiles_ap.where(\"percent_rank_ap > 0.01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------+\n",
      "|CARRIER|  count|percent_rank_aw|\n",
      "+-------+-------+---------------+\n",
      "|     HA|  83772|            0.0|\n",
      "|     G4| 104703|         0.0625|\n",
      "|     EV| 128711|          0.125|\n",
      "|     F9| 133393|         0.1875|\n",
      "|     NK| 201390|           0.25|\n",
      "|     YV| 221422|         0.3125|\n",
      "|     9E| 253104|          0.375|\n",
      "|     AS| 261693|         0.4375|\n",
      "|     OH| 282897|            0.5|\n",
      "|     B6| 293761|         0.5625|\n",
      "|     MQ| 316146|          0.625|\n",
      "|     YX| 321887|         0.6875|\n",
      "|     UA| 620767|           0.75|\n",
      "|     OO| 819738|         0.8125|\n",
      "|     AA| 927448|          0.875|\n",
      "|     DL| 990195|         0.9375|\n",
      "|     WN|1330598|            1.0|\n",
      "+-------+-------+---------------+\n",
      "\n",
      "+---------+------+-------+--------+-------------+------------------+---------------+\n",
      "|DEP_DELAY|ORIGIN|CARRIER|DEP_TIME|DEP_TIME_HOUR|   percent_rank_ap|percent_rank_aw|\n",
      "+---------+------+-------+--------+-------------+------------------+---------------+\n",
      "|      1.0|   MSY|     UA|    1608|           16|0.8997214484679665|           0.75|\n",
      "|     -5.0|   MSY|     UA|    1250|           12|0.8997214484679665|           0.75|\n",
      "|     43.0|   MSY|     UA|    1618|           16|0.8997214484679665|           0.75|\n",
      "|     -3.0|   MSY|     UA|    0815|           08|0.8997214484679665|           0.75|\n",
      "|     -5.0|   MSY|     UA|    0603|           06|0.8997214484679665|           0.75|\n",
      "|      6.0|   MSY|     UA|    1726|           17|0.8997214484679665|           0.75|\n",
      "|     -4.0|   MSY|     UA|    1951|           19|0.8997214484679665|           0.75|\n",
      "|     -9.0|   MSY|     UA|    0921|           09|0.8997214484679665|           0.75|\n",
      "|     -9.0|   MSY|     UA|    0626|           06|0.8997214484679665|           0.75|\n",
      "|     -6.0|   MSY|     UA|    1729|           17|0.8997214484679665|           0.75|\n",
      "|     78.0|   MSY|     UA|    1918|           19|0.8997214484679665|           0.75|\n",
      "|     -2.0|   MSY|     UA|    0653|           06|0.8997214484679665|           0.75|\n",
      "|     31.0|   MSY|     UA|    1927|           19|0.8997214484679665|           0.75|\n",
      "|     31.0|   MSY|     UA|    1144|           11|0.8997214484679665|           0.75|\n",
      "|     17.0|   MSY|     UA|    1617|           16|0.8997214484679665|           0.75|\n",
      "|      0.0|   MSY|     UA|    1152|           11|0.8997214484679665|           0.75|\n",
      "|      0.0|   MSY|     UA|    1413|           14|0.8997214484679665|           0.75|\n",
      "|     -7.0|   MSY|     UA|    0508|           05|0.8997214484679665|           0.75|\n",
      "|      8.0|   MSY|     UA|    1615|           16|0.8997214484679665|           0.75|\n",
      "|      0.0|   MSY|     UA|    1255|           12|0.8997214484679665|           0.75|\n",
      "+---------+------+-------+--------+-------------+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CARRIER\n",
    "#calculate percentiles\n",
    "percentiles_aw = flights_data.groupBy(\"CARRIER\").count()\\\n",
    "                .select(\"CARRIER\",\"count\", percent_rank().over(Window.partitionBy().orderBy(\"count\")).alias(\"percent_rank_aw\"))\n",
    "                \n",
    "percentiles_aw.show()\n",
    "\n",
    "#join percentiles_aw to initial dataset\n",
    "flights_percentiles_aw = flights_data.alias('flights').join(percentiles_aw.alias('percentiles'), col('percentiles.CARRIER') == col('flights.CARRIER'))\\\n",
    "            .select([col('flights.'+xx) for xx in flights_data.columns] + [col('percentiles.percent_rank_aw')])\n",
    "\n",
    "flights_percentiles_aw.show()\n",
    "\n",
    "\n",
    "#remove outliers (aka < 0.01) and store the rest on a new dataframe\n",
    "flights_data = flights_percentiles_aw.where(\"percent_rank_aw > 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string indexer ORIGIN\n",
    "\n",
    "indexer = StringIndexer()\\\n",
    ".setInputCol(\"ORIGIN\")\\\n",
    ".setOutputCol(\"ORIGIN_INDEXED\")\n",
    "\n",
    "# one hot encoder ORIGIN\n",
    "encoder = OneHotEncoder(dropLast=False)\\\n",
    ".setInputCols([\"ORIGIN_INDEXED\"])\\\n",
    ".setOutputCols([\"ORIGIN_ENCODED\"])\n",
    "\n",
    "\n",
    "# string indexer CARRIER\n",
    "\n",
    "indexer2 = StringIndexer()\\\n",
    ".setInputCol(\"CARRIER\")\\\n",
    ".setOutputCol(\"CARRIER_INDEXED\")\n",
    "\n",
    "# one hot encoder CARRIER\n",
    "encoder2 = OneHotEncoder(dropLast=False)\\\n",
    ".setInputCols([\"CARRIER_INDEXED\"])\\\n",
    ".setOutputCols([\"CARRIER_ENCODED\"])\n",
    "\n",
    "\n",
    "# string indexer DEP_TIME_HOUR\n",
    "\n",
    "indexer3 = StringIndexer()\\\n",
    ".setInputCol(\"DEP_TIME_HOUR\")\\\n",
    ".setOutputCol(\"DEP_TIME_HOUR_INDEXED\")\n",
    "\n",
    "\n",
    "# one hot encoder DEP_TIME_HOUR\n",
    "encoder3 = OneHotEncoder(dropLast=False)\\\n",
    ".setInputCols([\"DEP_TIME_HOUR_INDEXED\"])\\\n",
    ".setOutputCols([\"DEP_TIME_HOUR_ENCODED\"])\n",
    "\n",
    "\n",
    "# vector_assembler\n",
    "vector_assembler = VectorAssembler()\\\n",
    ".setInputCols([\"ORIGIN_ENCODED\", \"CARRIER_ENCODED\", \"DEP_TIME_HOUR_ENCODED\"])\\\n",
    ".setOutputCol(\"FEATURES\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the pipeline  \n",
    "pipe = Pipeline(stages=[indexer, encoder, indexer2, encoder2, indexer3, encoder3, vector_assembler])\n",
    "\n",
    "\n",
    "# Fit and transform the data\n",
    "piped_data = pipe.fit(flights_data).transform(flights_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "training, test = piped_data.randomSplit([.7, .3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.regression import LinearRegression \n",
    "lr = LinearRegression(featuresCol ='FEATURES', labelCol ='DEP_DELAY')\n",
    "#lr = LinearRegression(featuresCol ='FEATURES', labelCol ='DEP_DELAY',regParam=0.7, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.85794831476784"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the train and show the summary of the model\n",
    "lrModel = lr.fit(training)\n",
    "summary = lrModel.summary\n",
    "summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------+--------+-------------+-------------------+---------------+--------------+-----------------+---------------+---------------+---------------------+---------------------+--------------------+-------------------+\n",
      "|DEP_DELAY|ORIGIN|CARRIER|DEP_TIME|DEP_TIME_HOUR|    percent_rank_ap|percent_rank_aw|ORIGIN_INDEXED|   ORIGIN_ENCODED|CARRIER_INDEXED|CARRIER_ENCODED|DEP_TIME_HOUR_INDEXED|DEP_TIME_HOUR_ENCODED|            FEATURES|         prediction|\n",
      "+---------+------+-------+--------+-------------+-------------------+---------------+--------------+-----------------+---------------+---------------+---------------------+---------------------+--------------------+-------------------+\n",
      "|    -30.0|   RDU|     UA|    2035|           20| 0.9108635097493036|           0.75|          32.0| (355,[32],[1.0])|            4.0| (16,[4],[1.0])|                 14.0|      (24,[14],[1.0])|(395,[32,359,385]...| 25.074535279359033|\n",
      "|    -28.0|   SPN|     UA|    0847|           08|0.06128133704735376|           0.75|         336.0|(355,[336],[1.0])|            4.0| (16,[4],[1.0])|                  1.0|       (24,[1],[1.0])|(395,[336,359,372...|-3.1074951342738046|\n",
      "|    -28.0|   SPN|     UA|    0847|           08|0.06128133704735376|           0.75|         336.0|(355,[336],[1.0])|            4.0| (16,[4],[1.0])|                  1.0|       (24,[1],[1.0])|(395,[336,359,372...|-3.1074951342738046|\n",
      "|    -28.0|   SPN|     UA|    0847|           08|0.06128133704735376|           0.75|         336.0|(355,[336],[1.0])|            4.0| (16,[4],[1.0])|                  1.0|       (24,[1],[1.0])|(395,[336,359,372...|-3.1074951342738046|\n",
      "|    -27.0|   RNO|     UA|    1759|           17| 0.8161559888579387|           0.75|          64.0| (355,[64],[1.0])|            4.0| (16,[4],[1.0])|                  3.0|       (24,[3],[1.0])|(395,[64,359,374]...|  9.733120707562449|\n",
      "|    -27.0|   STT|     UA|    1458|           14| 0.5431754874651811|           0.75|         163.0|(355,[163],[1.0])|            4.0| (16,[4],[1.0])|                 10.0|      (24,[10],[1.0])|(395,[163,359,381...|  6.529847541057964|\n",
      "|    -26.0|   HDN|     UA|    1443|           14| 0.2924791086350975|           0.75|         253.0|(355,[253],[1.0])|            4.0| (16,[4],[1.0])|                 10.0|      (24,[10],[1.0])|(395,[253,359,381...| 20.402847201672678|\n",
      "|    -26.0|   PSP|     UA|    2244|           22| 0.7437325905292479|           0.75|          89.0| (355,[89],[1.0])|            4.0| (16,[4],[1.0])|                 17.0|      (24,[17],[1.0])|(395,[89,359,388]...| 29.841986075473077|\n",
      "|    -26.0|   SAV|     UA|    1304|           13| 0.7938718662952646|           0.75|          73.0| (355,[73],[1.0])|            4.0| (16,[4],[1.0])|                 12.0|      (24,[12],[1.0])|(395,[73,359,383]...| 14.700379478700103|\n",
      "|    -25.0|   KOA|     UA|    1340|           13| 0.7771587743732591|           0.75|         121.0|(355,[121],[1.0])|            4.0| (16,[4],[1.0])|                 12.0|      (24,[12],[1.0])|(395,[121,359,383...|  0.663420075830917|\n",
      "|    -25.0|   MEM|     UA|    1615|           16|  0.841225626740947|           0.75|          55.0| (355,[55],[1.0])|            4.0| (16,[4],[1.0])|                  9.0|       (24,[9],[1.0])|(395,[55,359,380]...| 15.794984396849461|\n",
      "|    -25.0|   PSP|     UA|    1757|           17| 0.7437325905292479|           0.75|          89.0| (355,[89],[1.0])|            4.0| (16,[4],[1.0])|                  3.0|       (24,[3],[1.0])|(395,[89,359,374]...| 14.592425915065817|\n",
      "|    -25.0|   SPN|     UA|    0850|           08|0.06128133704735376|           0.75|         336.0|(355,[336],[1.0])|            4.0| (16,[4],[1.0])|                  1.0|       (24,[1],[1.0])|(395,[336,359,372...|-3.1074951342738046|\n",
      "|    -25.0|   SPN|     UA|    0850|           08|0.06128133704735376|           0.75|         336.0|(355,[336],[1.0])|            4.0| (16,[4],[1.0])|                  1.0|       (24,[1],[1.0])|(395,[336,359,372...|-3.1074951342738046|\n",
      "|    -25.0|   SPN|     UA|    1800|           18|0.06128133704735376|           0.75|         336.0|(355,[336],[1.0])|            4.0| (16,[4],[1.0])|                 11.0|      (24,[11],[1.0])|(395,[336,359,382...| 7.9764102806868795|\n",
      "|    -24.0|   EWR|     UA|    2035|           20| 0.9526462395543176|           0.75|          17.0| (355,[17],[1.0])|            4.0| (16,[4],[1.0])|                 14.0|      (24,[14],[1.0])|(395,[17,359,385]...|  27.67099174200429|\n",
      "|    -24.0|   MYR|     UA|    1306|           13| 0.7381615598885793|           0.75|          92.0| (355,[92],[1.0])|            4.0| (16,[4],[1.0])|                 12.0|      (24,[12],[1.0])|(395,[92,359,383]...| 13.125817802793051|\n",
      "|    -24.0|   ORD|     UA|    2051|           20| 0.9972144846796658|           0.75|           1.0|  (355,[1],[1.0])|            4.0| (16,[4],[1.0])|                 14.0|      (24,[14],[1.0])|(395,[1,359,385],...| 24.275516736897274|\n",
      "|    -24.0|   PSP|     UA|    1324|           13| 0.7437325905292479|           0.75|          89.0| (355,[89],[1.0])|            4.0| (16,[4],[1.0])|                 12.0|      (24,[12],[1.0])|(395,[89,359,383]...| 12.514486301388258|\n",
      "|    -24.0|   SPN|     UA|    0851|           08|0.06128133704735376|           0.75|         336.0|(355,[336],[1.0])|            4.0| (16,[4],[1.0])|                  1.0|       (24,[1],[1.0])|(395,[336,359,372...|-3.1074951342738046|\n",
      "+---------+------+-------+--------+-------------+-------------------+---------------+--------------+-----------------+---------------+---------------+---------------------+---------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make predictions on test dataset\n",
    "predictions = lrModel.transform(test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------+-------------+-------------------+\n",
      "|DEP_DELAY|ORIGIN|CARRIER|DEP_TIME_HOUR|         prediction|\n",
      "+---------+------+-------+-------------+-------------------+\n",
      "|    -30.0|   RDU|     UA|           20| 25.074535279359033|\n",
      "|    -28.0|   SPN|     UA|           08|-3.1074951342738046|\n",
      "|    -28.0|   SPN|     UA|           08|-3.1074951342738046|\n",
      "|    -28.0|   SPN|     UA|           08|-3.1074951342738046|\n",
      "|    -27.0|   RNO|     UA|           17|  9.733120707562449|\n",
      "|    -27.0|   STT|     UA|           14|  6.529847541057964|\n",
      "|    -26.0|   HDN|     UA|           14| 20.402847201672678|\n",
      "|    -26.0|   PSP|     UA|           22| 29.841986075473077|\n",
      "|    -26.0|   SAV|     UA|           13| 14.700379478700103|\n",
      "|    -25.0|   KOA|     UA|           13|  0.663420075830917|\n",
      "+---------+------+-------+-------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TBD can be omitted\n",
    "final_df = predictions.select(\"DEP_DELAY\",\"ORIGIN\",\"CARRIER\",\"DEP_TIME_HOUR\",\"prediction\")\n",
    "final_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------------------+\n",
      "|         prediction|DEP_DELAY|            FEATURES|\n",
      "+-------------------+---------+--------------------+\n",
      "| 25.074535279359033|    -30.0|(395,[32,359,385]...|\n",
      "|-3.1074951342738046|    -28.0|(395,[336,359,372...|\n",
      "|-3.1074951342738046|    -28.0|(395,[336,359,372...|\n",
      "|-3.1074951342738046|    -28.0|(395,[336,359,372...|\n",
      "|  9.733120707562449|    -27.0|(395,[64,359,374]...|\n",
      "|  6.529847541057964|    -27.0|(395,[163,359,381...|\n",
      "| 20.402847201672678|    -26.0|(395,[253,359,381...|\n",
      "| 29.841986075473077|    -26.0|(395,[89,359,388]...|\n",
      "| 14.700379478700103|    -26.0|(395,[73,359,383]...|\n",
      "|  0.663420075830917|    -25.0|(395,[121,359,383...|\n",
      "+-------------------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.0516929\n",
      "Root Mean Squared Error (RMSE) on test data = 47.8972\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lrModel.transform(test)\n",
    "lr_predictions.select(\"prediction\",\"DEP_DELAY\",\"FEATURES\").show(10)\n",
    "\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"DEP_DELAY\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))\n",
    "\n",
    "test_result = lrModel.evaluate(test)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>2163876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>11.07030763315458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>49.18529507156865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>2064.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary          DEP_DELAY\n",
       "0   count            2163876\n",
       "1    mean  11.07030763315458\n",
       "2  stddev  49.18529507156865\n",
       "3     min              -52.0\n",
       "4     max             2064.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pandas\n",
    "#pip install pandas\n",
    "test.describe().toPandas()[[\"summary\",\"DEP_DELAY\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
