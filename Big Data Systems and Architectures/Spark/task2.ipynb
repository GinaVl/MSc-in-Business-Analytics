{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Big Data Systems and Architectures - Spark Assignment 2021</h2>\n",
    "<h3>Exploring International Flights in 2017 Data</h3>\n",
    "\n",
    "---\n",
    "> Georgia Vlassi p2822001<br />\n",
    "> Business Analytics <br />\n",
    "> Athens University of Economics and Business <br/>\n",
    "\n",
    "---\n",
    "\n",
    "The main scope of this assignment is to analyse a dataset about international flights in 2017, using Apache Spark to reveal insights about these data. \n",
    "\n",
    "You can find the aforementioned data here:\n",
    "http://andrea.imis.athena-innovation.gr/aueb-master/flights.csv.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 2</h3>\n",
    "The objective is to create reports on the \n",
    "average and median departure delays of (a) all the airports(ORIGIN), and (b) all the airways(CARRIER)in the \n",
    "dataset. You should give four reports, two for the airports (average/median delays) and two \n",
    "for the airways (average/median delays). Each report is a CSV file containing one line for each \n",
    "airport/airway and the lines of each file should be ordered (in descending order) based on the \n",
    "corresponding criterion (average/median delay). No header files are required for these files. \n",
    "An extra instruction you have from your supervisor is that you should take care of some data \n",
    "outliers: you should not consider in your analysis any airports/airways that have extremely \n",
    "low number of flights; the criterion is that any airport/airway belonging in the lowest 1% \n",
    "percentile, regarding the number of flights, should be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.readwriter import DataFrameReader\n",
    "from pyspark.sql.types import IntegerType, Row, StringType\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col,percent_rank,count,avg,expr,desc,round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to create a temporary view to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FlightsAssignment</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe269100310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"FlightsAssignment\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initialising the view we have to load our data. The data file named '671009038_T_ONTIME_REPORTING.csv', will be read by using using spark and save them into flights_data variable. In order to access the data download the file mentioned on description and unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_data = spark.read\\\n",
    "                    .option(\"header\",\"true\")\\\n",
    "                    .option(\"inferSchema\",\"true\")\\\n",
    "                    .csv(\"671009038_T_ONTIME_REPORTING.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+------+----------------+----+------------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+----+\n",
      "|   FL_DATE|TAIL_NUM|CARRIER|ORIGIN|ORIGIN_CITY_NAME|DEST|    DEST_CITY_NAME|DEP_TIME|DEP_DELAY|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|_c19|\n",
      "+----------+--------+-------+------+----------------+----+------------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+----+\n",
      "|2019-01-01|  N8974C|     9E|   AVL|   Asheville, NC| ATL|       Atlanta, GA|    1658|     -7.0|    1758|    -22.0|      0.0|             null|     0.0|         null|         null|     null|          null|               null|null|\n",
      "|2019-01-01|  N922XJ|     9E|   JFK|    New York, NY| RDU|Raleigh/Durham, NC|    1122|     -8.0|    1255|    -29.0|      0.0|             null|     0.0|         null|         null|     null|          null|               null|null|\n",
      "+----------+--------+-------+------+----------------+----+------------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_data.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7422037"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset should be cleaned. As mentioned, there are airports, which have very few flights. More specific we have to omit the airports in the lowest 1% percentile in the number of flights.\n",
    "\n",
    "In the beginning, we will count the percentiles of the flights each airport has.\n",
    "\n",
    "<h4>ORIGIN</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+\n",
      "|ORIGIN|count|     percent_rank_ap|\n",
      "+------+-----+--------------------+\n",
      "|   AKN|   61|                 0.0|\n",
      "|   PGV|   80|0.002785515320334262|\n",
      "|   DLG|   82|0.005571030640668524|\n",
      "|   GST|   82|0.005571030640668524|\n",
      "|   HYA|   83|0.011142061281337047|\n",
      "+------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate percentiles\n",
    "percentiles_ap = flights_data.groupBy(\"ORIGIN\").count()\\\n",
    "                .select(\"ORIGIN\",\"count\", percent_rank().over(Window.partitionBy().orderBy(\"count\")).alias(\"percent_rank_ap\"))\n",
    "                \n",
    "percentiles_ap.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count before removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7422037"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_before = flights_data.count()\n",
    "flights_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+------+----------------+----+--------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+----+-------------------+\n",
      "|   FL_DATE|TAIL_NUM|CARRIER|ORIGIN|ORIGIN_CITY_NAME|DEST|DEST_CITY_NAME|DEP_TIME|DEP_DELAY|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|_c19|    percent_rank_ap|\n",
      "+----------+--------+-------+------+----------------+----+--------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+----+-------------------+\n",
      "|2019-01-01|  N629BR|     OO|   BGM|  Binghamton, NY| DTW|   Detroit, MI|    1743|     -4.0|    1940|      9.0|      0.0|             null|     0.0|         null|         null|     null|          null|               null|null|0.24512534818941503|\n",
      "|2019-01-01|  N919EV|     OO|   BGM|  Binghamton, NY| DTW|   Detroit, MI|    1221|    -12.0|    1358|    -22.0|      0.0|             null|     0.0|         null|         null|     null|          null|               null|null|0.24512534818941503|\n",
      "|2019-01-02|  N914EV|     OO|   BGM|  Binghamton, NY| DTW|   Detroit, MI|     553|     -7.0|     753|      3.0|      0.0|             null|     0.0|         null|         null|     null|          null|               null|null|0.24512534818941503|\n",
      "|2019-01-02|  N8982A|     OO|   BGM|  Binghamton, NY| DTW|   Detroit, MI|    1815|     28.0|    2004|     28.0|      0.0|             null|     0.0|          0.0|          0.0|      0.0|           1.0|               27.0|null|0.24512534818941503|\n",
      "|2019-01-02|  N8932C|     OO|   BGM|  Binghamton, NY| DTW|   Detroit, MI|    1317|     44.0|    1507|     44.0|      0.0|             null|     0.0|          0.0|          0.0|      0.0|           0.0|               44.0|null|0.24512534818941503|\n",
      "+----------+--------+-------+------+----------------+----+--------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#join percentiles to initial dataset\n",
    "flights_percentiles_ap = flights_data.alias('flights').join(percentiles_ap.alias('percentiles'), col('percentiles.ORIGIN') == col('flights.ORIGIN'))\\\n",
    "            .select([col('flights.'+xx) for xx in flights_data.columns] + [col('percentiles.percent_rank_ap')])\n",
    "\n",
    "flights_percentiles_ap.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers (aka < 0.01) and store the rest on a new dataframe\n",
    "flights_data = flights_percentiles_ap.where(\"percent_rank_ap > 0.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count after removing outlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7421732"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_after_ap = flights_data.count()\n",
    "flights_after_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each airport calculate the average DEP_DELAY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|ORIGIN|AverageDelay|\n",
      "+------+------------+\n",
      "|   OTH|       33.78|\n",
      "|   XWA|        32.6|\n",
      "|   MMH|       30.97|\n",
      "|   HYA|       29.35|\n",
      "|   MEI|       28.88|\n",
      "|   ACK|       28.15|\n",
      "|   EGE|       26.46|\n",
      "|   MQT|       26.19|\n",
      "|   HGR|       25.18|\n",
      "|   CMX|       24.05|\n",
      "|   ACV|       23.68|\n",
      "|   SHD|       23.59|\n",
      "|   OGS|       23.41|\n",
      "|   OGD|        23.3|\n",
      "|   ASE|       23.24|\n",
      "|   SLN|       22.85|\n",
      "|   SWF|       22.18|\n",
      "|   BLV|       21.48|\n",
      "|   CKB|       21.41|\n",
      "|   STC|       21.32|\n",
      "+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg,expr, col, desc,round\n",
    "\n",
    "avgDelayPerAirport = flights_data\\\n",
    "               .groupBy(\"ORIGIN\")\\\n",
    "               .agg(round(avg((\"DEP_DELAY\")),2).alias(\"AverageDelay\"))\\\n",
    "               .sort(desc(\"AverageDelay\"))\n",
    "avgDelayPerAirport.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgDelayPerAirport.limit(100).coalesce(1)\\\n",
    "       .write.csv(\"task2-ap-avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each airport calculate the median DEP_DELAY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|ORIGIN|MedianDelay|\n",
      "+------+-----------+\n",
      "|   ADK|        8.0|\n",
      "|   OGD|        7.0|\n",
      "|   HYA|        3.0|\n",
      "|   PPG|        3.0|\n",
      "|   MDW|        2.0|\n",
      "|   DAL|        1.0|\n",
      "|   HOU|        1.0|\n",
      "|   LCK|        0.0|\n",
      "|   BLV|        0.0|\n",
      "|   BWI|        0.0|\n",
      "|   AZA|        0.0|\n",
      "|   OAK|        0.0|\n",
      "|   XWA|        0.0|\n",
      "|   ART|        0.0|\n",
      "|   HGR|        0.0|\n",
      "|   SCK|        0.0|\n",
      "|   STL|        0.0|\n",
      "|   HTS|        0.0|\n",
      "|   PSM|       -1.0|\n",
      "|   MSY|       -1.0|\n",
      "+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medDelayPerAirport = flights_data\\\n",
    "                .groupBy(\"ORIGIN\")\\\n",
    "                .agg(expr('percentile_approx(DEP_DELAY, 0.5)').alias(\"MedianDelay\"))\\\n",
    "                .sort(desc(\"MedianDelay\"))\n",
    "medDelayPerAirport.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "medDelayPerAirport.limit(100).coalesce(1)\\\n",
    "       .write.csv(\"task2-ap-med\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset should be cleaned. As mentioned, there are airports, which have very few flights. More specific we have to omit the airports in the lowest 1% percentile in the number of flights.\n",
    "\n",
    "In the beginning, we will count the percentiles of the flights each airway has.\n",
    "\n",
    "<h4>CARRIER</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------------+\n",
      "|CARRIER| count|percent_rank_aw|\n",
      "+-------+------+---------------+\n",
      "|     HA| 83891|            0.0|\n",
      "|     G4|105305|         0.0625|\n",
      "|     EV|134683|          0.125|\n",
      "|     F9|135543|         0.1875|\n",
      "|     NK|204845|           0.25|\n",
      "+-------+------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate percentiles\n",
    "percentiles_aw = flights_data.groupBy(\"CARRIER\").count()\\\n",
    "                .select(\"CARRIER\",\"count\", percent_rank().over(Window.partitionBy().orderBy(\"count\")).alias(\"percent_rank_aw\"))\n",
    "                \n",
    "percentiles_aw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7421732"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_after_aw = flights_data.count()\n",
    "flights_after_aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+------+----------------+----+-----------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+----+------------------+---------------+\n",
      "|   FL_DATE|TAIL_NUM|CARRIER|ORIGIN|ORIGIN_CITY_NAME|DEST|   DEST_CITY_NAME|DEP_TIME|DEP_DELAY|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|_c19|   percent_rank_ap|percent_rank_aw|\n",
      "+----------+--------+-------+------+----------------+----+-----------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+----+------------------+---------------+\n",
      "|2019-01-01|  N484UA|     UA|   MSY| New Orleans, LA| DEN|       Denver, CO|    1608|      1.0|    1758|     -3.0|      0.0|             null|     0.0|         null|         null|     null|          null|               null|null|0.8997214484679665|           0.75|\n",
      "|2019-01-01|  N896UA|     UA|   MSY| New Orleans, LA| IAD|   Washington, DC|    1250|     -5.0|    1604|     -8.0|      0.0|             null|     0.0|         null|         null|     null|          null|               null|null|0.8997214484679665|           0.75|\n",
      "|2019-01-01|  N821UA|     UA|   MSY| New Orleans, LA| SFO|San Francisco, CA|    1618|     43.0|    1903|     38.0|      0.0|             null|     0.0|         38.0|          0.0|      0.0|           0.0|                0.0|null|0.8997214484679665|           0.75|\n",
      "|2019-01-01|  N456UA|     UA|   MSY| New Orleans, LA| DEN|       Denver, CO|     815|     -3.0|    1004|     -8.0|      0.0|             null|     0.0|         null|         null|     null|          null|               null|null|0.8997214484679665|           0.75|\n",
      "|2019-01-01|  N470UA|     UA|   MSY| New Orleans, LA| EWR|       Newark, NJ|     603|     -5.0|     932|    -18.0|      0.0|             null|     0.0|         null|         null|     null|          null|               null|null|0.8997214484679665|           0.75|\n",
      "+----------+--------+-------+------+----------------+----+-----------------+--------+---------+--------+---------+---------+-----------------+--------+-------------+-------------+---------+--------------+-------------------+----+------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#join percentiles_aw to initial dataset\n",
    "flights_percentiles_aw = flights_data.alias('flights').join(percentiles_aw.alias('percentiles'), col('percentiles.CARRIER') == col('flights.CARRIER'))\\\n",
    "            .select([col('flights.'+xx) for xx in flights_data.columns] + [col('percentiles.percent_rank_aw')])\n",
    "\n",
    "flights_percentiles_aw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers (aka < 0.01) and store the rest on a new dataframe\n",
    "flights_data = flights_percentiles_aw.where(\"percent_rank_aw > 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7337841"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_after_aw = flights_data.count()\n",
    "flights_after_aw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate with the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|CARRIER|AverageDelay|\n",
      "+-------+------------+\n",
      "|     B6|       17.75|\n",
      "|     EV|       17.21|\n",
      "|     F9|       14.58|\n",
      "|     YV|        13.8|\n",
      "|     UA|        13.0|\n",
      "|     OO|       12.56|\n",
      "|     AA|       12.11|\n",
      "|     NK|       10.94|\n",
      "|     OH|        10.7|\n",
      "|     9E|       10.25|\n",
      "|     WN|       10.18|\n",
      "|     G4|       10.12|\n",
      "|     MQ|        9.27|\n",
      "|     YX|        8.54|\n",
      "|     DL|        8.16|\n",
      "|     AS|        5.04|\n",
      "+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg,expr, col, desc, round\n",
    "\n",
    "avgDelayPerAirway = flights_data\\\n",
    "               .groupBy(\"CARRIER\")\\\n",
    "               .agg(round(avg((\"DEP_DELAY\")),2).alias(\"AverageDelay\"))\\\n",
    "               .sort(desc(\"AverageDelay\"))\n",
    "avgDelayPerAirway.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate with the dataset omitted outliers (SAME results) - No need to check outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgDelayPerAirway.limit(100).coalesce(1)\\\n",
    "       .write.csv(\"task2-aw-avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|CARRIER|MedianDelay|\n",
      "+-------+-----------+\n",
      "|     WN|        0.0|\n",
      "|     AA|       -2.0|\n",
      "|     DL|       -2.0|\n",
      "|     B6|       -3.0|\n",
      "|     NK|       -3.0|\n",
      "|     OH|       -3.0|\n",
      "|     MQ|       -3.0|\n",
      "|     UA|       -3.0|\n",
      "|     G4|       -3.0|\n",
      "|     F9|       -3.0|\n",
      "|     YV|       -3.0|\n",
      "|     OO|       -3.0|\n",
      "|     EV|       -4.0|\n",
      "|     AS|       -4.0|\n",
      "|     9E|       -4.0|\n",
      "|     YX|       -4.0|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medDelayPerAirway = flights_data\\\n",
    "                .groupBy(\"CARRIER\")\\\n",
    "                .agg(expr('percentile_approx(DEP_DELAY, 0.5)').alias(\"MedianDelay\"))\\\n",
    "                .sort(desc(\"MedianDelay\"))\n",
    "medDelayPerAirway.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "medDelayPerAirway.limit(100).coalesce(1)\\\n",
    "       .write.csv(\"task2-aw-med\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
